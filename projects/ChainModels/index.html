<html>
<head>
<style type="text/css">
/* Stolen from Sergey stolen from Jon Barron */
body
{
background-color:#FFFFFF;
color:#222222;
}
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 14px
  }
  strong {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 13px
  }
  heading {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 15px;
        font-weight: 700
  }

  h5 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700;
    color: orange;
  }
  </style>

<title>Chain Models</title>

</head>

<body>
<h2>Chained Predictions Using Convolutional Neural Networks</h2>
<h4>May, 2016</h4>

<p style="text-align: center;">
<img height=266 src="model_1.png" />
<img height=266 src="model_2.png" />
</p>

<h4>Abstract</h4>
<p>
In this paper, we present an adaptation of the sequence-to-sequence model for
structured output prediction in vision tasks. In this model the output variables
for a given input are predicted sequentially using neural networks. The prediction
for each output variable depends not only on the input but also on the previously 
predicted output variables. The model is applied to spatial
localization tasks and uses convolutional neural networks (CNNs) for processing input images
and a multi-scale deconvolutional architecture for making spatial predictions at each time
step. We explore the impact of weight sharing with a recurrent
connection matrix between consecutive predictions, and compare it to a formulation where
these weights are not tied. Untied weights are particularly suited for problems with a
fixed sized structure, where different classes of output are predicted in different steps.
We show that chained predictions achieve top performing results on human pose estimation from single images and videos.
<br /><br />
<a href="http://arxiv.org/pdf/1605.02346v1.pdf">paper</a>
</p>

<hr />

<h4> Image Pose Predictions </h4>
<p style="text-align: center;">
<img height=150 src="mpii_examples_2.png" />
<img height=150 src="mpii_examples_4.png" />
<img height=150 src="mpii_examples_3.png" />
</p>

<hr />

<h4> Video Pose Predictions </h4>

<p style="text-align: center;">
<img height=100 src="out1.gif" />
<img height=100 src="out119.gif" />
<img height=100 src="out201.gif" />
<img height=100 src="out268.gif" />
<img height=100 src="out596.gif" />
<img height=100 src="out713.gif" />
<img height=100 src="out750.gif" />
<img height=100 src="out898.gif" />
<img height=100 src="out927.gif" />
<img height=100 src="out2247.gif" />
<img height=100 src="out2308.gif" />
</p>

<hr />
<h4>How to cite</h4>

<p>
<tt>
 @inproceedings{chain16, <br />
  &nbsp; Author = {G. Gkioxari and A. Toshev and N. Jaitly},<br />
  &nbsp; Title = {Chained Predictions Using Convolutional Neural Networks},<br />
  &nbsp; Booktitle = {arXiv preprint arXiv:1605.02346},<br />
  &nbsp; Year = {2016}}
</tt>
</p>

<hr />

<h4>Contact</h4>
<p>
For any questions regarding the work or the implementation, contact the author at gkioxari@eecs.berkeley.edu 
</p>

</body>

</html>
