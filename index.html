<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>

<head>
  <link rel="shortcut icon" type="image/x-icon" href="teasers/favicon.ico" />
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

  <title>Georgia Gkioxari</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
  <script type="text/javascript" src="js/hidebib.js"></script>

  <script type="text/javascript">

    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-40545479-1']);
    _gaq.push(['_trackPageview']);

    (function () {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

  </script>

  <script async defer src="https://buttons.github.io/buttons.js"></script>

</head>

<body>
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center">
              <font size="6px">Georgia Gkioxari</font><br>
              georgia.gkioxari@gmail.com
            </p>

            <p align=justify>I am an Assistant Professor of <a href="https://www.cms.caltech.edu/">Computing +
                Mathematical Sciences</a> at <a href="https://www.caltech.edu/">Caltech</a> and a William H. Hurt
              scholar. I am also a visiting researcher at Meta AI in the Embodied AI team. From 2016 to 2022, I was a
              research scientist at
              Meta's <a href="https://research.facebook.com/ai/">FAIR</a> team. I received my PhD from <a
                href="http://www.berkeley.edu/">UC Berkeley</a>, where I was advised by <a
                href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I did my bachelors in <a
                href="http://www.ece.ntua.gr/">ECE</a> at <a href="http://www.ntua.gr/">NTUA</a> in Athens, Greece,
              where I worked with <a href="http://cvsp.cs.ntua.gr/maragos/">Petros Maragos</a>.</p>

            <p align=justify> I am the recipient of the <a
                href="https://tc.computer.org/tcpami/young-researcher-award/#:~:text=This%20annual%20award%20recognizes%20a,the%20PAMI%2DTC%20awards%20committee.">PAMI
                Young Researcher Award</a> (2021). My teammates and I received the <a
                href="https://tc.computer.org/tcpami/mark-everingham-prize/#:~:text=This%20Prize%20is%20to%20commemorate,%3A%2F%2Fbit.ly%2Fmarkever.">PAMI
                Mark Everingham Award</a> (2021) for the Detectron Library Suite. I was named one of 30 influential
              women advancing AI in 2019 by <a href="https://blog.re-work.co/top-women-in-ai-2019/">ReWork</a> and was
              nominated for the Women in AI Awards in 2020 by <a
                href="https://venturebeat.com/2020/07/15/announcing-nominees-for-the-second-annual-women-in-ai-awards/">VentureBeat</a>.
              Read more about me and my work in this <a
                href="https://ai.facebook.com/blog/qa-with-georgia-gkioxari-winner-of-the-2021-pami-young-researcher-award">Q&A</a>.
            </p>

            <p>
              <a href="cv_gkioxari.pdf"><img src="icons/cv.png" height="16"></a> /
              <a href="https://twitter.com/georgiagkioxari"><img src="icons/twitter.png" height="16"></a> /
              <a href="https://www.linkedin.com/in/georgia-gkioxari-16967b20" target="_blank"><img
                  src="icons/linkedin.png" height="16"></a> /
              <a href="https://scholar.google.com/citations?user=kQisE-gAAAAJ&hl=en" target="_blank"><img
                  src="icons/google_scholar.png" height="16"></a> /
              <a href="https://github.com/gkioxari/" target="_blank"><img src="icons/github_alt.png" height="16"></a>
            </p>
          </td>
          <td width="30%">
            <div class="instructorphoto">
              <img onmouseover="document.getElementById('georgia').src='teasers/me_at_ark.jpeg';"
                onmouseout="document.getElementById('georgia').src='teasers/me_at_ark.jpeg';"
                src="teasers/me_at_ark.jpeg" id="georgia">
            </div>
          </td>
        </tr>
      </table>
    </table>
  </div>
  <br>

  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
      <h2>Research Highlights</h2>
      <div class="research">
        <p align=justify> <strong>The goal of my work is to design visual perception models that bridge the gap between
            2D imagery and
            our 4D world</strong>. My research interests lie in computer vision and machine learning. I want to build
          intelligent systems that perceive the world from as little as one single image -- just like humans do!
          Our world is complex, it is three dimensional and it is dynamic.
          Computational models get to observe this world from imagery but only partially as visual data does not
          completely
          capture the richness of the world we live in. Below I highlight work that attempts to transform visual data to
          semantic scene representations in 2D and 3D.
        <ul align="justify">
          <li><span><strong>Visual Recognition in 2D: </strong> Models that recognize objects and their location (<a
                href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a>),
              humans, their actions (<a href="https://arxiv.org/abs/1505.01197">R*CNN</a>) and interactions with other
              objects (<a href="https://arxiv.org/abs/1704.07333">InteractNet</a>), all from a single image.</span>
          </li>
          <li><span><strong>Visual Recognition in 3D:</strong> Models that recognize objects in their natural continuous
              3D metric space. <a href="https://arxiv.org/abs/2207.10660">Omni3D</a> tackles 3D object detection for
              over 90 categories from a single image, <a href="https://arxiv.org/abs/2112.01520">ViewSeg</a>
              performs semantic segmentation in 3D from as few as 4 images.</span></li>
          <li><span><strong>3D Reconstruction:</strong> Models that recognize objects and their 3D geometry from a
              single view, in the form of meshes (<a href="https://arxiv.org/abs/1906.02739">Mesh R-CNN</a>) and point
              clouds (<a href="https://arxiv.org/abs/2301.08247">MCC</a>).</span></li>
          <li><span><strong>Novel Learning Paradigms for 3D:</strong> Semi-supervised and un-supervised learning
              techniques to train single-image 3D recognition models that learn from video (<a
                href="https://arxiv.org/abs/2206.07028">USL</a>). Multi-view optimization for 3D shape and texture
              inference with ideas from
              traditional stereopsis (<a href="https://arxiv.org/abs/2110.05472">DS</a>) </span></li>
          <li><span><strong>Tooling:</strong> <a href="https://github.com/facebookresearch/pytorch3d">PyTorch3D</a> for
              3D deep learning.</span></li>
        </ul>
        </p>
      </div>
    </table>
  </div>
  <br>

  <div class="container">
    <p align=justify> <strong>Caltech students (undergrads and grads):</strong> If you are at Caltech and wish to work
      with me,
      please read the information in this <a
        href="https://docs.google.com/document/d/1AJrIuXnVmzqOGwTTXGSIr3IgF8K_3E4zIQQZ1QSdk7M/edit?usp=sharing">doc</a>.
    </p>

    <p align=justify> <strong>Prospective postdocs:</strong> If you
      are interested in a postdoc position and want to conduct research in computer vision, 3D understanding and visual
      perception, please contact me directly with your CV and a short research statement.
    </p>

    <p align=justify> <strong>Prospective PhD students:</strong> I am looking for Ph.D. students to join my group. If
      you are interested in my group, please <a href="https://gradoffice.caltech.edu/admissions/applyonline">apply</a>
      directly to the CMS department and mention my name in your statement of purpose. There is no need to email me.
    </p>
  </div>
  <br>

  <div class="container">
    <div class="students">
      <h2>Students</h2>
      <table width="90%" align="center">
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/sabera.jpg">
          </div>
          <a href="https://saberatalukder.com/">Sabera Talukder</a> <br> NSF GR & Chen Fellow <br> <br>
        </td>
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/guanzhi.png">
          </div>
          <a href="https://guanzhi.me/">Guanzhi Wang</a> <br> <br> <br>
        </td>
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/ilona.jpg">
          </div>
          <a href="https://ilonadem.github.io/id-folio/">Ilona Demler</a> <br> NSF GR & EAS
          Scholar <br> <br>
        </td>
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/Damiano.jpg">
          </div>
          <a href="">Damiano Marsili</a> <br> <br> <br>
        </td>
      </table>
      <table width="70%" align="center">
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/aadarsh.jpg">
          </div>
          <a href="https://aadsah.github.io/">Aadarsh Sahoo</a> <br> Kortschak Scholar <br> <br>
        </td>
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/raphi.jpg">
          </div>
          <a href="https://www.raphikang.com/">Raphi Kang</a> <br> NSF GR<br> <br>
        </td>
        <td width="25%" align="center">
          <div class="instructorphotosmall">
            <img src="teasers/students/ziqi.jpeg">
          </div>
          <a href="https://ziqi-ma.github.io/">Ziqi Ma</a> <br> Kortschak Scholar <br> <br>
        </td>
      </table>
    </div>
  </div>
  <br>

  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
      <h2>News</h2>
      <div class="news">
        <ul>
          <li><span>Thank you Okawa Foundation for the <a
                href="http://www.okawa-foundation.or.jp/en/activities/research_grant/list.html">
                Okawa Research Grant</a>. </span></li>
          <li><span>Thank you Google for the <a
                href="https://research.google/programs-and-events/research-scholar-program/recipients/?filtertab=2024">Google
                Faculty Scholar</a> award. </span></li>
          <li><span>Thank you Amazon for the <a
                href="https://www.amazon.science/research-awards/program-updates/99-amazon-research-awards-recipients-announced">Amazon
                Research Award</a>.</span></li>
          <li><span>Check out our discussion about AI and its portrayal in Hollywood movies: <a
                href="https://www.youtube.com/watch?v=_1pl8VWpZUA">Sci-Fi to Sci-Fact: Artificial Intelligence on the
                Big Screen</a></span></li>
          <li><span>Saining and I organized the <a href="https://gkioxari.github.io/Tutorials/iccv2023/">"Quo
                Vadis, Computer Vision?"</a> workshop at ICCV 2023.</span></li>
        </ul>
      </div>
    </table>
  </div>
  <br>

  <div class="container">
    <h2> Teaching at Caltech </h2>
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="30%"><img src="teasers/eecs148.png" alt="llvm" width="180"></td>
        <td width="70%" valign="center">
          <p>
            <a href="https://gkioxari.github.io/teaching/cs148_sp2023/"><b>EE/CS 148 - Spring 2023: Large Language and
                Vision Models</b></a>
          </p>
          <p>
            <a href="https://gkioxari.github.io/teaching/cs148/"><b>EE/CS 148 - Spring 2024: Large Language and
                Vision Models</b></a>
          </p>

        </td>
      </table>
      <br>
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="30%"><img src="teasers/cs101.gif" alt="3dclass" width="180"></td>
        <td width="70%" valign="center">
          <p>
            <a
              href="https://docs.google.com/spreadsheets/d/1TyeekhGqWQhUjdvz3jPoj-NgDZQhp1_I8fCHVlMJE6o/edit?usp=sharing"><b>CS
                101 - Winter 2024: Learning & 3D</b></a>
          </p>
        </td>
      </table>
    </div>
  </div>
  <br>


  <div class="container">
    <h2>Libraries</h2>
    <div class="news">
      <table width="90%" border="0" align="center" cellpadding="20">
        <tr>
          <td width="45%" style="text-align: center" valign="center"><img width="400" src="teasers/pytorch3dlogo.png">
          </td>
          <td width="45%" style="text-align: center" valign="center"><img width="400" src="teasers/detectronlogo.png">
          </td>
        </tr>
        <tr>
          <td width="40%" style="text-align: center">
            <a class="github-button" href="https://github.com/facebookresearch/pytorch3d" data-icon="octicon-star"
              data-size="large" data-show-count="true" aria-label="Star ntkme/github-buttons on GitHub">Star</a>
          </td>
          <td width="40%" style="text-align: center">
            <a class="github-button" href="https://github.com/facebookresearch/detectron" data-icon="octicon-star"
              data-size="large" data-show-count="true" aria-label="Star ntkme/github-buttons on GitHub">Star</a>
            <a class="github-button" href="https://github.com/facebookresearch/detectron2" data-icon="octicon-star"
              data-size="large" data-show-count="true" aria-label="Star ntkme/github-buttons on GitHub">Star</a>
          </td>
      </table>
    </div>
  </div>
  <br>

  <div class="container">
    <h2> Selected Publications </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><video width="175" src="teasers/parq_teaser.mp4" title="PARQ" playsinline=""
            autoplay="" loop="" preload="" muted=""></video></td>
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2310.01401.pdf" style="color: #0047AB"><b>Pixel-Aligned Recurrent Queries
                for Multi-View 3D Object
                Detection</b></a><br>
            <a href="https://ymingxie.github.io/">Yiming Xie</a>, <a href="https://ymingxie.github.io/">
              Huaizu Jiang</a>, <a href="http://people.csail.mit.edu/jstraub/"> Julian Straub*</a>, <strong> Georgia
              Gkioxari</strong>*<br>
            <em>International Conference of Computer Vision (ICCV)</em>, 2023 <br>

          <div class="paper" id="parq">
            <a href="https://arxiv.org/abs/2310.01401">arxiv</a> /
            <a href="https://ymingxie.github.io/parq/">project page</a> /
            <a href="https://github.com/ymingxie/parq">code</a> /
            <a shape="rect" href="javascript:togglebib('parq')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{xie2023pixel,
  title={Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection},
  author={Xie, Yiming and Jiang, Huaizu and Gkioxari, Georgia and Straub, Julian},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={18370--18380},
  year={2023}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/spyro.jpg" alt="game" width="75"
            style="border-style: none"><img src="teasers/spyro.gif" alt="game" width="100" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2301.08247.pdf" style="color: #0047AB"><b>Multiview Compressive Coding for
                3D Reconstruction</b></a><br>
            <a href="https://chaoyuan.org/">Chao-Yuan Wu</a>, <a href="https://web.eecs.umich.edu/~justincj/"> Justin
              Johnson</a>, <a href="https://people.eecs.berkeley.edu/~malik/"> Jitendra Malik</a>, <a
              href="https://feichtenhofer.github.io/"> Christoph
              Feichtenhofer</a>, <strong> Georgia Gkioxari</strong><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023 <br>

          <div class="paper" id="mcc3d">
            <a href="https://arxiv.org/abs/2301.08247">arxiv</a> /
            <a href="https://mcc3d.github.io/">project page</a> /
            <a href="https://github.com/facebookresearch/MCC">code</a> /
            <a shape="rect" href="javascript:togglebib('mcc3d')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{wu2023multiview,
  author    = {Wu, Chao-Yuan and Johnson, Justin and Malik, Jitendra and Feichtenhofer, Christoph and Gkioxari, Georgia},
  title     = {Multiview Compressive Coding for 3{D} Reconstruction},
  journal   = {CVPR},
  year      = {2023},
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/omni3d_aria.gif" alt="game" width="180"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2207.10660.pdf" style="color: #0047AB"><b>Omni3D: A Large Benchmark and
                Model for 3D Object Detection in the Wild</b></a><br>
            <a href="https://garrickbrazil.com/">Garrick Brazil</a>,
            <a href="https://sites.google.com/view/abhinavkumar">Abhinav Kumar</a>,
            <a href="http://people.csail.mit.edu/jstraub/"> Julian Straub</a>,
            <a href="https://github.com/nikhilaravi"> Nikhila Ravi</a>,
            <a href="https://web.eecs.umich.edu/~justincj/"> Justin Johnson</a>,
            <strong> Georgia Gkioxari</strong>
            <br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023 <br>

          <div class="paper" id="omni3d">
            <a href="https://arxiv.org/abs/2207.10660">arxiv</a> /
            <a href="https://garrickbrazil.com/omni3d/">project page</a> /
            <a href="https://github.com/facebookresearch/omni3d">code</a> /
            <a shape="rect" href="javascript:togglebib('omni3d')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{brazil2022omni3d,
  title={{Omni3D}: A Large Benchmark and Model for {3D} Object Detection in the Wild},
  author={Garrick Brazil and Abhinav Kumar and Julian Straub and Nikhila Ravi and Justin Johnson and Georgia Gkioxari},
  journal={CVPR},
  year={2023}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/video3d_short.gif" alt="game" width="180"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2206.07028.pdf" style="color: #0047AB"><b>Learning 3D Object Shape and
                Layout without 3D Supervision</b></a><br>
            <strong> Georgia Gkioxari</strong>, <a href="https://github.com/nikhilaravi"> Nikhila Ravi</a>, <a
              href="https://web.eecs.umich.edu/~justincj/"> Justin Johnson</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2022 <br>

          <div class="paper" id="video3d">
            <a href="https://arxiv.org/abs/2206.07028">arxiv</a> /
            <a href="usl/index.html">project page</a> /
            <a href="https://youtu.be/PKhGIiMuRJU">video</a> /
            <a shape="rect" href="javascript:togglebib('video3d')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{usl2022,
  title={Learning 3D Object Shape and Layout without 3D Supervision},
  author={Georgia Gkioxari and Nikhila Ravi and Justin Johnson},
  journal={CVPR},
  year={2022}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/dsteaser.png" alt="game" width="180" height="120"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2110.05472.pdf" style="color: #0047AB"><b>Differentiable Stereopsis:
                Meshes
                from multiple views using differentiable rendering</b></a><br>
            <a href="https://people.eecs.berkeley.edu/~shubham-goel/"> Shubham Goel</a>, <strong> Georgia
              Gkioxari</strong>, <a href="https://people.eecs.berkeley.edu/~malik/"> Jitendra Malik</a> <br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2022 <br>

          <div class="paper" id="ds">
            <a href="https://arxiv.org/abs/2110.05472">arxiv</a> /
            <a href="https://shubham-goel.github.io/ds/">project page</a> /
            <a href="https://github.com/shubham-goel/ds">code</a> /
            <a shape="rect" href="javascript:togglebib('ds')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{goel2022ds,
  title={Differentiable Stereopsis: Meshes from multiple views using differentiable rendering},
  author={Shubham Goel and Georgia Gkioxari and Jitendra Malik},
  journal={CVPR},
  year={2022}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/viewseg1.png" alt="game" width="100" height="80"
            style="border-style: none">
        <td width="40%" valign="center"><img src="teasers/viewseg2.gif" alt="game" width="80" height="80"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2112.01520.pdf" style="color: #0047AB"><b>Recognizing Scenes from Novel
                Viewpoints</b></a><br>
            <a href="https://jasonqsy.github.io/"> Shengyi Qian</a>, <a href="https://alexander-kirillov.github.io/">
              Alexander Kirillov</a>, <a href="https://github.com/nikhilaravi"> Nikhila Ravi</a>, <a
              href="https://devendrachaplot.github.io/"> Devendra Singh Chaplot</a>, <a
              href="https://web.eecs.umich.edu/~justincj/"> Justin Johnson</a>, <a
              href="https://web.eecs.umich.edu/~fouhey/"> David F. Fouhey</a>, <strong> Georgia Gkioxari</strong><br>

          <div class="paper" id="viewseg">
            <a href="https://arxiv.org/abs/2112.01520">arxiv</a> /
            <a href="https://jasonqsy.github.io/viewseg/">project page</a> /
            <a href="https://github.com/facebookresearch/viewseg">code</a> /
            <a shape="rect" href="javascript:togglebib('viewseg')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{qian2021viewseg,
  title={Recognizing Scenes from Novel Viewpoints},
  author={Shengyi Qian and Alexander Kirillov and Nikhila Ravi and Devendra Singh Chaplot and Justin Johnson and David Fouhey and Georgia Gkioxari},
  journal={arXiv preprint arXiv:2112.01520},
  year={2021}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/pytorch3dlogo.png" alt="game" width="200" height="50"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://github.com/facebookresearch/pytorch3d" style="color: #0047AB"><b>PyTorch3D</b></a><br>
            <a href="https://github.com/nikhilaravi">Nikhila Ravi</a>, <a href="https://github.com/bottler">Jeremy
              Reizenstein</a>, <a href="https://github.com/davnov134">David Novotny</a>, Taylor Gordon, <a
              href="https://github.com/wanyenlo">Wan-Yen Lo</a>, <a href="https://github.com/jcjohnson"> Justin
              Johnson</a>*, <strong> Georgia Gkioxari</strong>* <br>

          <div class="paper" id="pytorch3d">
            <a
              href="https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/">blog</a>
            /
            <a href="http://arxiv.org/abs/2007.08501">arxiv</a> /
            <a href="https://github.com/facebookresearch/pytorch3d">code</a> /
            <a href="https://pytorch3d.org/">project page</a> /
            <a shape="rect" href="javascript:togglebib('pytorch3d')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{ravi2020accelerating,
  title={Accelerating 3D Deep Learning with PyTorch3D},
  author={Ravi, Nikhila and Reizenstein, Jeremy and Novotny, David and Gordon, 
          Taylor and Lo, Wan-Yen and Johnson, Justin and Gkioxari, Georgia},
  journal={arXiv preprint arXiv:2007.08501},
  year={2020}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/visiontouch.png" alt="game" width="180" height="80"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2007.03778.pdf" style="color: #0047AB"><b>3D Shape Reconstruction from
                Vision and Touch</b></a><br>
            <a href="https://edwardsmith1884.github.io/">Edward J. Smith</a>, <a
              href="https://www.robertocalandra.com/about/">Roberto Calandra</a>, <a
              href="https://sites.google.com/site/adriromsor/home">Adriana Romero</a>, <strong>Georgia
              Gkioxari</strong>, <a href="https://mila.quebec/en/person/david-meger/">David Meger</a>, <a
              href="https://people.eecs.berkeley.edu/~malik/"> Jitendra Malik</a>, <a
              href="https://www.linkedin.com/in/michal-drozdzal-a36b9b42/?originalSubdomain=ca">Michal Drozdal</a>
            <br>
            <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020 <br>

          <div class="paper" id="visiontouch">
            <a href="https://arxiv.org/abs/2007.03778">arxiv</a> /
            <a href="https://github.com/facebookresearch/3D-Vision-and-Touch">code</a> /
            <a shape="rect" href="javascript:togglebib('visiontouch')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{smith20203d,
  title={3D Shape Reconstruction from Vision and Touch},
  author={Smith, Edward J and Calandra, Roberto and Romero, Adriana and Gkioxari, 
          Georgia and Meger, David and Malik, Jitendra and Drozdzal, Michal},
  Booktitle={NeurIPS},
  year={2020}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="http://www.robots.ox.ac.uk/~ow/videos/media5.gif" alt="game"
            width="90" height="60" style="border-style: none"><img
            src="http://www.robots.ox.ac.uk/~ow/videos/media2.gif" alt="game" width="90" height="60"
            style="border-style: none"><img src="http://www.robots.ox.ac.uk/~ow/videos/media16.gif" alt="game"
            width="90" height="60" style="border-style: none"><img
            src="http://www.robots.ox.ac.uk/~ow/videos/media25.gif" alt="game" width="90" height="60"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1912.08804" style="color: #0047AB"><b>SynSin: End-to-end View Synthesis
                from
                a Single Image</b></a><br>
            <a href="http://www.robots.ox.ac.uk/~ow">Olivia Wiles</a>, <strong> Georgia Gkioxari</strong>, <a
              href="https://research.fb.com/people/szeliski-richard/"> Richard Szeliski</a>, <a
              href="https://cs.stanford.edu/people/jcjohns/"> Justin Johnson</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2020 <strong>(oral)</strong><br>

          <div class="paper" id="synsin">
            <a href="https://arxiv.org/abs/1912.08804">arxiv</a> /
            <a href="https://github.com/facebookresearch/synsin">code</a> /
            <a href="http://www.robots.ox.ac.uk/~ow/synsin.html">project page</a> /
            <a shape="rect" href="javascript:togglebib('synsin')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{synsin,
Title={{SynSin}: {E}nd-to-end View Synthesis from a Single Image},,
Author={Olivia Wiles, Georgia Gkioxari, Richard Szeliski, Justin Johnson},
Booktitle={CVPR},
Year={2020}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/meshrcnn.gif" alt="game" width="190" height="110"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1906.02739.pdf" style="color: #0047AB"><b>Mesh R-CNN</b></a><br>
            <strong> Georgia Gkioxari</strong>, <a href="https://people.eecs.berkeley.edu/~malik/"> Jitendra
              Malik</a>,
            <a href="https://cs.stanford.edu/people/jcjohns/"> Justin Johnson</a><br>
            <em>International Conference of Computer Vision (ICCV)</em>, 2019 <br>

          <div class="paper" id="meshrcnn">
            <a href="https://arxiv.org/abs/1906.02739">arxiv</a> /
            <a href="https://github.com/facebookresearch/meshrcnn">code</a> /
            <a href="meshrcnn/index.html">project page</a> /
            <a
              href="https://docs.google.com/presentation/d/18yd22C2RCs_dACrRL01r1eqHq9FrGwPXQAokq6QqSjE/edit?usp=sharing">examples</a>
            /
            <a shape="rect" href="javascript:togglebib('meshrcnn')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{meshrcnn,
Title={Mesh R-CNN},
Author={Georgia Gkioxari, Jitendra Malik, Justin Johnson},
Booktitle={ICCV},
Year={2019}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="https://wijmans.xyz/img/eqa-matter-tease.png" alt="game" width="190"
            height="150" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1904.03461.pdf" style="color: #0047AB"><b>Embodied Question Answering in
                Photorealistic Environments with Point Cloud Perception</b></a><br>
            <a href="https://wijmans.xyz/">Erik Wijmans</a>, <a href="http://samyak-268.github.io/"> Samyak Datta</a>,
            <a href="https://research.fb.com/people/maksymets-oleksandr/"> Oleksandr Maksymets</a>, <a
              href="http://abhishekdas.com/"> Abhishek Das</a>, <strong> Georgia Gkioxari</strong>, <a
              href="https://www.cc.gatech.edu/~slee3191/"> Stefan Lee</a>, <a href="http://prof.irfanessa.com/"> Irfan
              Essa</a>, <a href="https://www.cc.gatech.edu/~parikh/"> Devi Parikh</a>, <a
              href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2019 <strong>(oral)</strong><br>

          <div class="paper" id="matterport">
            <a href="https://arxiv.org/abs/1904.03461">arxiv</a> /
            <a href="http://embodiedqa.org/"> project page</a> /
            <a shape="rect" href="javascript:togglebib('matterport')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{wijmans2019,
Title={Embodied Question Answering in Photorealistic Environments with Point Cloud Perception},
Author={Erik Wijmans and Samyak Datta and Oleksandr Maksymets and Georgia Gkioxari
        and Stefan Lee and Irfan Essa and Devi Parikh and Dhruv Batra},
Booktitle={CVPR},
Year={2019}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/mteqa.png" alt="game" width="180" height="120"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1904.04686.pdf" style="color: #0047AB"><b>Multi-Target Embodied Question
                Answering</b></a><br>
            <a href="http://www.cs.unc.edu/~licheng/">Licheng Yu</a>, <a href="http://xinleic.xyz/"> Xinlei Chen</a>,
            <strong> Georgia Gkioxari</strong>, <a href="http://www.cs.unc.edu/~mbansal/"> Mohit Bansal</a>, <a
              href="http://tamaraberg.com/"> Tamara Berg</a>, <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv
              Batra</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2019 <br>

          <div class="paper" id="mteqa">
            <a href="https://arxiv.org/abs/1904.04686">arxiv</a> /
            <a href="http://embodiedqa.org/"> project page</a> /
            <a shape="rect" href="javascript:togglebib('mteqa')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{mteqa,
Title={Multi-Target Embodied Question Answering},
Author={Licheng Yu and Xinlei Chen and Georgia Gkioxari and Mohit Bansal and Tamara Berg and Dhruv Batra},
Booktitle={CVPR},
Year={2019}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/nmc.png" alt="game" width="180" height="140"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1810.11181.pdf" style="color: #0047AB"><b>Neural Modular Control for
                Embodied Question Answering</b></a><br>
            <a href="http://abhishekdas.com/"> Abhishek Das</a>, <strong> Georgia Gkioxari</strong>, <a
              href="https://www.cc.gatech.edu/~slee3191/"> Stefan Lee</a>, <a href="https://www.cc.gatech.edu/~parikh/">
              Devi Parikh</a>, <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>
            <em>Conference on Robot Learning (CoRL)</em>, 2018<br>

          <div class="paper" id="nmc">
            <a href="https://arxiv.org/abs/1810.11181">arxiv</a> /
            <a href="http://embodiedqa.org/"> project page</a> /
            <a shape="rect" href="javascript:togglebib('nmc')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{nmc,
Title={{N}eural {M}odular {C}ontrol for {E}mbodied {Q}uestion {A}nswering},
Author={Abhishek Das and Georgia Gkioxari 
        and Stefan Lee and Devi Parikh and Dhruv Batra},
Booktitle={CoRL},
Year={2018}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/house3D.gif" alt="game" width="180" height="140"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1801.02209.pdf" style="color: #0047AB"><b>Building Generalizable Agents
                With
                a Realistic And Rich 3D Environment</b></a><br>
            <a href="https://jxwuyi.weebly.com/"> Yi Wu</a>, <a href="https://github.com/ppwwyyxx"> Yuxin Wu</a>,
            <strong>Georgia Gkioxari</strong>, <a href="http://yuandong-tian.com/"> Yuandong Tian</a><br>
            <em>International Conference on Learning Representations (ICLR), Workshop Track</em>, 2018<br>

          <div class="paper" id="house3D">
            <a href="https://arxiv.org/abs/1801.02209">arxiv</a> /
            <a href="https://github.com/facebookresearch/House3D"> code</a> /
            <a shape="rect" href="javascript:togglebib('house3D')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{wu2018house3D,
Author    = {Yi Wu and Yuxin Wu and 
            Georgia Gkioxari and Yuandong Tian},
Title     = {Building Generalizable Agents With a Realistic And Rich 3D Environment},
Journal   = {arXiv preprint arXiv:1801.02209},
Year      = {2018}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/interactnet_teaser.png" alt="game" width="180" height="130"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1704.07333.pdf" style="color: #0047AB"><b>Detecting and Recognizing
                Human-Object Interactions</b></a><br>
            <strong>Georgia Gkioxari</strong>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a>, <a
              href="https://pdollar.github.io/"> Piotr Doll&agraver</a> and <a href="http://kaiminghe.com/"> Kaiming
              He</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <strong>(spotlight)</strong><br>

          <div class="paper" id="interactnet">
            <a href="https://arxiv.org/abs/1704.07333">arxiv</a> /
            <a href="InteractNet/index.html">project page</a> /
            <a shape="rect" href="javascript:togglebib('interactnet')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{gkioxari2017interactnet,
Author    = {Georgia Gkioxari and Ross Girshick and 
             Piotr Doll\'{a}r and Kaiming He},
Title     = {Detecting and Recognizing Human-Object Intaractions},
Booktitle = {CVPR},
Year      = {2018}}
              </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/embodiedqa.gif" alt="game" width="180" height="130"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1711.11543.pdf" style="color: #0047AB"><b>Embodied Question
                Answering</b></a><br>
            <a href="http://abhishekdas.com/"> Abhishek Das</a>, <a href="http://samyak-268.github.io/"> Samyak
              Datta</a>,<strong> Georgia Gkioxari</strong>, <a href="https://www.cc.gatech.edu/~slee3191/"> Stefan
              Lee</a>, <a href="https://www.cc.gatech.edu/~parikh/"> Devi Parikh</a>, <a
              href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <strong>(oral)</strong><br>

          <div class="paper" id="embodiedqa">
            <a href="https://arxiv.org/abs/1711.11543">arxiv</a> /
            <a href="http://embodiedqa.org/"> project page</a> /
            <a href="https://github.com/facebookresearch/EmbodiedQA"> code</a> /
            <a shape="rect" href="javascript:togglebib('embodiedqa')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{embodiedqa,
Title={{E}mbodied {Q}uestion {A}nswering},
Author={Abhishek Das and Samyak Datta and 
          Georgia Gkioxari and Stefan Lee and 
          Devi Parikh and Dhruv Batra},
Booktitle={CVPR},
Year={2018}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/posetrack1.gif" alt="game" width="180" height="80"
            style="border-style: none" align="middle">
          <img src="teasers/posetrack2.gif" alt="game" width="180" height="80" style="border-style: none"
            align="middle">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1712.09184.pdf" style="color: #0047AB"><b>Detect-and-Track: Efficient Pose
                Estimation in Videos</b></a><br>
            <a href="http://rohitgirdhar.github.io/"> Rohit Girdhar</a>, <strong>Georgia Gkioxari</strong>, <a
              href="http://www.cs.dartmouth.edu/~lorenzo/home.html"> Lorenzo Torresani</a>, <a
              href="https://research.fb.com/people/paluri-manohar/"> Manohar Paluri</a> and <a
              href="http://www.cs.dartmouth.edu/~dutran/"> Du Tran</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>

          <div class="paper" id="posetrack">
            <a href="https://arxiv.org/abs/1712.09184">arxiv</a> /
            <a href="https://github.com/facebookresearch/DetectAndTrack/">code</a> /
            <a shape="rect" href="javascript:togglebib('posetrack')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{girdhar2018,
Title={Detect-and-Track: Efficient Pose Estimation in Videos,
Author={Rohit Girdhar and Georgia Gkioxari and 
        Lorenzo Torresani and Manohar Paluri and Du Tran},
Booktitle={CVPR},
Year={2018}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/dd.png" alt="game" width="190" height="90"
            style="border-style: none" valign="middle">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1712.04440.pdf" style="color: #0047AB"><b>Data Distillation: Towards
                Omni-Supervised Learning</b></a><br>
            Ilija Radosavovic, <a href="https://pdollar.github.io/"> Piotr Doll&agraver</a>, <a
              href="http://www.rossgirshick.info/"> Ross Girshick</a>, <strong>Georgia Gkioxari</strong> and <a
              href="http://kaiminghe.com/"> Kaiming He</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>

          <div class="paper" id="datadistillation">
            <a href="https://arxiv.org/abs/1712.04440">arxiv</a> /
            <a shape="rect" href="javascript:togglebib('datadistillation')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{dd,
Title={Data Distillation: Towards Omni-Supervised Learning,
Author={Ilija Radosavovic and Piotr Doll\'{a}r and
        Ross Girshick and Georgia Gkioxari and 
        Kaiming He},
Booktitle={CVPR},
Year={2018}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/mrcnn_teaser.png" alt="game" width="180" height="140"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1703.06870.pdf" style="color: #0047AB"><b>Mask R-CNN</b></a><br>
            <a href="http://kaiminghe.com/"> Kaiming He</a>, <strong>Georgia Gkioxari</strong>, <a
              href="https://pdollar.github.io/"> Piotr Doll&agraver</a> and <a href="http://www.rossgirshick.info/">
              Ross Girshick</a><br>
            <em>International Conference of Computer Vision (ICCV)</em>, 2017 <strong>(oral)</strong><br>
            <mark>Best Paper Award (Marr Prize)</mark> &nbsp

          <div class="paper" id="maskrcnn">
            <a href="https://arxiv.org/abs/1703.06870">arxiv</a> /
            <a href="https://github.com/facebookresearch/Detectron"> code</a> /
            <a shape="rect" href="javascript:togglebib('maskrcnn')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{he2017maskrcnn,
Author    = {Kaiming He and Georgia Gkioxari and
         Piotr Doll\'{a}r and Ross Girshick},
Title     = {Mask R-CNN},
Booktitle   = {ICCV},
Year      = {2017}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/learn2smile.png" alt="game" width="180" height="140"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.dropbox.com/s/ljfnv3i1jw0uzbh/learn2smile-learning-verbal.pdf?dl=0"
              style="color: #0047AB"><b>Learn2Smile: Learning Non-verbal Interaction through Observation</b></a><br>
            Will Feng, Anitha Kannan, <strong>Georgia Gkioxari</strong>, <a href="http://larryzitnick.org/"> Larry
              Zitnick</a><br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2017
            <strong>(oral)</strong><br>
            <mark>Finalist for the JTCF Novel Technology Paper Award For Amusement Culture</mark> &nbsp

          <div class="paper" id="learn2smile">
            <a shape="rect" href="javascript:togglebib('learn2smile')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{learn2smile2017,
Author    = {Will Feng, Anitha Kannan, Georgia Gkioxari and Larry Zitnick},
Title     = {Learn2Smile: Learning Non-verbal Interaction through Observation},
Booktitle = {IROS},
Year      = {2017}}
              </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>


    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="ChainModels/out596.gif" alt="game" width="180" height="90"
            style="border-style: none" align="middle">
          <img src="ChainModels/out2247.gif" alt="tennis" width="180" height="90" style="border-style: none"
            align="middle">
        <td width="60%" valign="top">
          <p><a href="http://arxiv.org/pdf/1605.02346v2.pdf" style="color: #0047AB"><b>Chained Predictions Using
                Convolutional Neural Networks</b></a><br>
            <strong>Georgia Gkioxari</strong>, <a href="https://research.google.com/pubs/AlexanderToshev.html">Alexander
              Toshev</a> and <a href="http://www.cs.toronto.edu/~ndjaitly">Navdeep Jaitly</a><br>
            <em>European Conference of Computer Vision (ECCV)</em>, 2016 &nbsp

          <div class="paper" id="chain">
            <a href="http://arxiv.org/abs/1605.02346">arxiv</a> /
            <a href="ChainModels/index.html">project page</a> /
            <a shape="rect" href="javascript:togglebib('chain')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{chain16,
Author = {G. Gkioxari and A. Toshev and N. Jaitly},
Title = {Chained Predictions Using 
       Convolutional Neural Networks},
Booktitle = {ECCV},
Year = {2016}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/frstarcnn.png" alt="rstarcnn" width="180" height="160"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/1505.01197.pdf" style="color: #0047AB"><b>Contextual Action Recognition
                with
                R*CNN</b></a><br>
            <strong>Georgia Gkioxari</strong>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a
              href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>
            <em>International Conference of Computer Vision (ICCV)</em>, 2015 &nbsp

          <div class="paper" id="rstarcnn">
            <a href="http://arxiv.org/abs/1505.01197">arxiv</a> /
            <a href="https://github.com/gkioxari/RstarCNN">code</a> /
            <a shape="rect" href="javascript:togglebib('rstarcnn')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{rstarcnn,
Author = {G. Gkioxari and R. Girshick and J. Malik},
Title = {Contextual Action Recognition with R*CNN},
Booktitle = {ICCV},
Year = {2015}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><a href="deepparts.gif"><img src="teasers/deepparts.gif" alt="deepparts"
              width="180" height="110" style="border-style: none"></a>
        <td width="60%" valign="top">
          <p><a href="https://www.dropbox.com/s/jovtmei1is10r05/deepparts_camera_ready.pdf?dl=0"
              style="color: #0047AB"><b>Actions and Attributes from Wholes and Parts</b></a><br>
            <strong>Georgia Gkioxari</strong>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a
              href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>
            <em>International Conference of Computer Vision (ICCV)</em>, 2015 &nbsp

          <div class="paper" id="deepparts">
            <a href="http://arxiv.org/abs/1412.2604">arxiv</a> /
            <a shape="rect" href="javascript:togglebib('deepparts')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{deepparts,
Author = {G. Gkioxari and R. Girshick and J. Malik},
Title = {Actions and Attributes from Wholes and Parts},
Booktitle = {ICCV},
Year = {2015}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/fat.png" alt="fat" width="180" height="120"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.dropbox.com/s/jf9oukcm893e72g/action_tubes.pdf?dl=0" style="color: #0047AB"><b>Finding
                Action Tubes</b></a><br>
            <strong>Georgia Gkioxari</strong> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2015 &nbsp

          <div class="paper" id="ActionCNN">
            <a href="ActionTubes/index.html">project page</a> /
            <a href="http://arxiv.org/abs/1411.6031">arxiv</a> /
            <a href="https://github.com/gkioxari/ActionTubes">code</a> /
            <a href="ActionTubes/NegativeResults.txt">negative results</a> /
            <a
              href="http://nbviewer.ipython.org/github/gkioxari/ActionTubes/blob/master/test_tubes/UCFsports_benchmark/UCFsports_auc.ipynb">UCF
              Sports Benchmark</a> /
            <a shape="rect" href="javascript:togglebib('ActionCNN')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@inproceedings{actiontubes,
Author = {G. Gkioxari and J. Malik},
Title = {Finding Action Tubes},
Booktitle = {CVPR},
Year = {2015}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/multiloss.png" alt="multiloss" width="180" height="120"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.dropbox.com/s/nv2o0hpdt9n8fak/multiloss.pdf?dl=0" style="color: #0047AB"><b>R-CNNs
                for
                Pose Estimation and Action Detection</b></a><br>
            <strong>Georgia Gkioxari</strong>, <a href="http://www.cs.berkeley.edu/~bharath2/">Bharath Hariharan</a>,
            <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a href="http://www.cs.berkeley.edu/~malik/">
              Jitendra Malik</a><br>

          <div class="paper" id="multiloss">
            <a href="PersonNet/index.html">project page</a> /
            <a href="http://arxiv.org/abs/1406.5212">arxiv</a> /
            <a shape="rect" href="javascript:togglebib('multiloss')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@article{poseactionrcnn,
Author = {G. Gkioxari and B. Hariharan
    and R. Girshick and J. Malik},
Title = {R-CNNs for Pose Estimation and Action Detection},
ArchivePrefix = {arXiv},
Eprint = {1406.5212},
PrimaryClass = {cs.CV},
Year = {2014}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/kposelets.png" alt="kposelets" width="180" height="120"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.dropbox.com/s/db88eb3i4hsl1a4/kposelets.pdf?dl=0" style="color: #0047AB"><b>Using
                k-poselets for detecting people and localizing their keypoints</b></a><br>
            <strong>Georgia Gkioxari*</strong>, <a href="http://www.cs.berkeley.edu/~bharath2/">Bharath
              Hariharan*</a>,
            <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a href="http://www.cs.berkeley.edu/~malik/">
              Jitendra Malik</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2014 &nbsp <br>
            <strong> * authors contributed equally</strong>

          <div class="paper" id="kposelets">
            <a href="kposelets/index.html">project page</a> /
            <a href="https://www.dropbox.com/s/jqveoqso6572av7/kposelets-release.tar.gz?dl=0">code</a> /
            <a href="https://github.com/gkioxari/k-poselets">github</a> /
            <a href="https://www.dropbox.com/s/0kn3f0mfudj9qk9/kposelets-spotlight.mp4?dl=0">spotlight</a> /
            <a shape="rect" href="javascript:togglebib('kposelets')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@inproceedings{kposelets,
Author = {G. Gkioxari and B. Hariharan 
      and R. Girshick and J. Malik},
Title = {Using k-poselets for  detecting people and 
      localizing their keypoints},
Booktitle = {CVPR},
Year = {2014}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/armlets.png" alt="armlets" width="180" height="120"
            style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.dropbox.com/s/r6vb6ace88hhrh9/GkioxariCVPR2013.pdf?dl=0"
              style="color: #0047AB"><b>Articulated Pose Estimation using Discriminative Armlet
                Classifiers</b></a><br>
            <strong>Georgia Gkioxari</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/"> Pablo Arbelaez</a>, <a
              href="http://www.lubomir.org/"> Lubomir Bourdev</a> and <a href="http://www.cs.berkeley.edu/~malik/">
              Jitendra Malik</a><br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2013 &nbsp

          <div class="paper" id="armlets">
            <a href="https://www.dropbox.com/s/bddbv8g5n427clt/armlets_slides.pptx?dl=0">slides</a> /
            <a shape="rect" href="javascript:togglebib('armlets')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@inproceedings{armlets,
Author = {G. Gkioxari and P. Arbelaez 
      and L. Bourdev and J. Malik},
Title  = {Articulated Pose Estimation using 
      Discriminative Armlet Classifiers},
Booktitle = {CVPR},
Year  = {2013}}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
  </div>
  <br>

  <div class="container">
    <h2> Teaching at UC Berkeley </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%"><img src="teasers/pacman.png" alt="pacman" width="180" height="140"></td>
        <td width="60%" valign="center">
          <p>
            <a href="http://inst.eecs.berkeley.edu/~cs188/fa11/announcements.html"><b>CS188 - Fall 2011 </a> (GSI -<a
              href="http://gsi.berkeley.edu/programs-services/award-programs/ogsi/ogsi-2012/"> GSI Outstanding
              Award</a>)</b><br>

          </p>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%"><img src="teasers/pipe_icon.jpg" alt="pipe" width="180" height="140"></td>
        <td width="60%" valign="center">
          <p>
            <a><b>CS 280 - Fall 2012 </a>(GSI)</b><br>
          </p>
        </td>
      </table>
    </div>
  </div>
  <br>

  <div class="containersmall">
    <p style="text-align:right;">Stolen from <a href="https://jonbarron.info/">Jon Barron</a></p>
  </div>

  <script xml:space="preserve" language="JavaScript">
    hideallbibs();
  </script>


</body>

</html>